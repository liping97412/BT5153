{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8H3mJIWHVNPP"
   },
   "source": [
    "# Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQsBa-43VNPQ"
   },
   "source": [
    "## What is NLP?\n",
    "\n",
    "- Using computers to process (analyze, understand, generate) natural human languages\n",
    "- Most knowledge created by humans is unstructured text, and we need a way to make sense of it\n",
    "- Build probabilistic model using data about a language\n",
    "- Requires an understanding of language and the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "krQQD5nDVNPR"
   },
   "source": [
    "## Higher level \"task areas\"\n",
    "\n",
    "- **Information retrieval**: Find relevant results and similar results\n",
    "    - [Google](https://www.google.com/)\n",
    "- **Information extraction**: Structured information from unstructured documents\n",
    "    - [Events from Gmail](https://support.google.com/calendar/answer/6084018?hl=en)\n",
    "- **Machine translation**: One language to another\n",
    "    - [Google Translate](https://translate.google.com/)\n",
    "- **Text simplification**: Preserve the meaning of text, but simplify the grammar and vocabulary\n",
    "    - [Rewordify](https://rewordify.com/)\n",
    "    - [Simple English Wikipedia](https://simple.wikipedia.org/wiki/Main_Page)\n",
    "- **Predictive text input**: Faster or easier typing\n",
    "    - [A much better application](https://farsite.shinyapps.io/swiftkey-cap/)\n",
    "- **Sentiment analysis**: Attitude of speaker\n",
    "    - [Hater News](http://haternews.herokuapp.com/)\n",
    "- **Automatic summarization**: Extractive or abstractive summarization\n",
    "    - [autotldr](https://www.reddit.com/r/technology/comments/35brc8/21_million_people_still_use_aol_dialup/cr2zzj0)\n",
    "- **Natural Language Generation**: Generate text from data\n",
    "    - [How a computer describes a sports match](http://www.bbc.com/news/technology-34204052)\n",
    "    - [Publishers withdraw more than 120 gibberish papers](http://www.nature.com/news/publishers-withdraw-more-than-120-gibberish-papers-1.14763)\n",
    "- **Speech recognition and generation**: Speech-to-text, text-to-speech\n",
    "    - [Google's Web Speech API demo](https://www.google.com/intl/en/chrome/demos/speech.html)\n",
    "    - [Vocalware Text-to-Speech demo](https://www.vocalware.com/index/demo)\n",
    "- **Question answering**: Determine the intent of the question, match query with knowledge base, evaluate hypotheses\n",
    "    - [How did supercomputer Watson beat Jeopardy champion Ken Jennings?](http://blog.ted.com/how-did-supercomputer-watson-beat-jeopardy-champion-ken-jennings-experts-discuss/)\n",
    "    - [IBM's Watson Trivia Challenge](http://www.nytimes.com/interactive/2010/06/16/magazine/watson-trivia-game.html)\n",
    "    - [The AI Behind Watson](http://www.aaai.org/Magazine/Watson/watson.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vim_QrvpVNPS"
   },
   "source": [
    "## Lower level \"components\"\n",
    "\n",
    "- **Tokenization**: breaking text into tokens (words, sentences, n-grams)\n",
    "- **Stop word removal**: removing common words\n",
    "- **TF-IDF**: computing word importance\n",
    "- **Stemming and lemmatization**: reducing words to their base form\n",
    "- **Part-of-speech tagging**\n",
    "- **Named entity recognition**: person/organization/location\n",
    "- **Segmentation**: \"New York City subway\"\n",
    "- **Word sense disambiguation**: \"buy a mouse\"\n",
    "- **Spelling correction**\n",
    "- **Language detection**\n",
    "- **Machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M56VjTwxVNPT"
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. Reading in the Yelp reviews corpus\n",
    "2. Tokenizing the text\n",
    "3. Comparing the accuracy of different approaches\n",
    "4. Removing frequent terms (stop words)\n",
    "5. Removing infrequent terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRn5y-guVNPW"
   },
   "source": [
    "## Part 1: Reading in the Yelp reviews corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbaYTyDDVNPX"
   },
   "source": [
    "- \"corpus\" = collection of documents\n",
    "- \"corpora\" = plural form of corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jwi1-Ey8VNPX"
   },
   "outputs": [],
   "source": [
    "# read yelp.csv into a DataFrame using a relative path\n",
    "import pandas as pd\n",
    "path = \"../BT5153_data/yelp.csv\"\n",
    "yelp = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1544275425123,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "t_SNjuyCVNPa",
    "outputId": "48aa8ed8-ac3d-4fd0-e248-83232f5b7037"
   },
   "outputs": [],
   "source": [
    "# examine the first three rows\n",
    "yelp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the last three rows\n",
    "yelp.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1544275495463,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "yjQk9stqVNPe",
    "outputId": "e079795e-2a15-4800-f85c-a776a4bed1fd"
   },
   "outputs": [],
   "source": [
    "# examine the text for the first row\n",
    "yelp.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzIHzN52VNPh"
   },
   "source": [
    "**Goal:** Distinguish between 5-star and 1-star reviews using **only** the review text. (We will not be using the other columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1090,
     "status": "ok",
     "timestamp": 1544275510163,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "vtjOb-Q_VNPh",
    "outputId": "d45dba72-3048-4890-bb2e-a0b7d48f3d5f"
   },
   "outputs": [],
   "source": [
    "# examine the class distribution\n",
    "# value_counts() return the data type as Pandas Series\n",
    "yelp.stars.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLYlzEhMVNPj"
   },
   "outputs": [],
   "source": [
    "# create a new DataFrame that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1544275785317,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "bWz8NsivVNPl",
    "outputId": "be2b8067-b0da-4076-c3d9-8f1e441e2bea"
   },
   "outputs": [],
   "source": [
    "# examine the shape\n",
    "yelp_best_worst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8X6ZQ34VNPo"
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urAQGyROVNPq"
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBTvQW4GVNPu",
    "outputId": "451ae6e2-815b-4599-b71c-ba6508aa0ca6"
   },
   "outputs": [],
   "source": [
    "# examine the object shapes\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1544276113818,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "8NmCNK9KBoae",
    "outputId": "017fda2f-5bd2-4a24-f90f-1b1a81ffc805"
   },
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAG8rOYHVNPx"
   },
   "source": [
    "## Part 2: Tokenizing the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqTB7xFuVNPy"
   },
   "source": [
    "- **What:** Separate text into units such as words, n-grams, or sentences\n",
    "- **Why:** Gives structure to previously unstructured text\n",
    "- **Notes:** Relatively easy with English language text, not easy with some languages\n",
    "- **Some Chinese text Tokenization Tools**\n",
    "\n",
    "https://github.com/thunlp/THULAC\n",
    "\n",
    "https://github.com/fxsjy/jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2-EXopiVNPy"
   },
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SPazJzmVNP0"
   },
   "outputs": [],
   "source": [
    "# fit and transform X_train\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kK4UoBwDVNP3"
   },
   "outputs": [],
   "source": [
    "# only transform X_test\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 759,
     "status": "ok",
     "timestamp": 1544276162933,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "SBe68vKlVNP6",
    "outputId": "78feb6e4-1117-484e-feee-d36fa951832a"
   },
   "outputs": [],
   "source": [
    "# examine the shapes: rows are documents, columns are terms (aka \"tokens\" or \"features\")\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1544276246223,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "yC6-KEk9CTQe",
    "outputId": "eb6db21e-fdd7-47ab-9526-c87b8a396d27"
   },
   "outputs": [],
   "source": [
    "type(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J7gHylQqVNP9",
    "outputId": "51f7639d-ad4e-4efd-a5ee-6952d21d39ce"
   },
   "outputs": [],
   "source": [
    "# examine the last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "406lnqsaVNQA",
    "outputId": "e2d6e835-8f03-43de-803a-dc8577958a6f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKFCZJw_VNQB"
   },
   "source": [
    "[CountVectorizer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RUb-ZHRVNQC"
   },
   "source": [
    "- **lowercase:** boolean, True by default\n",
    "    - Convert all characters to lowercase before tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1544276365754,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "_8OSOoFOVNQD",
    "outputId": "cdc242df-75d6-4549-eb45-81e97c4442f9"
   },
   "outputs": [],
   "source": [
    "# don't convert to lowercase\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKgs2n76VNQF"
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2483,
     "status": "ok",
     "timestamp": 1544276375425,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "QaOS4u4qVNQG",
    "outputId": "cf206eda-4431-4e94-857f-f1a0271ca48d"
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1544276380036,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "uZ6UcfagVNQI",
    "outputId": "79055e5a-fbbb-4566-e69a-3df83bfaaf12"
   },
   "outputs": [],
   "source": [
    "# examine the last 50 features\n",
    "print(vect.get_feature_names()[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfEX5PB6VNQK"
   },
   "source": [
    "## Part 3: Comparing the accuracy of different approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTICtxVNVNQL"
   },
   "source": [
    "**Approach 1:** Always predict the most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1544276579128,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "IfWh4E38DN_M",
    "outputId": "c643e4fe-56cf-4167-a1ff-4b9069026c11"
   },
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1544276387727,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "tRp2aqgWVNQM",
    "outputId": "7418aeee-e1e1-40ee-980f-db0e5c81070d"
   },
   "outputs": [],
   "source": [
    "# calculate null accuracy\n",
    "y_test.value_counts().head(1) / y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1544276420931,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "XxFzTTFLVNQO",
    "outputId": "5367d155-1f8e-44e0-9187-8a3aab1e352e"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "\n",
    "dummy.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_pred_class = dummy.predict(X_test_dtm)\n",
    "\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is 81% good enough? \n",
    "Accuracy sometimes is a misleading indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8KEfGMLVNQQ"
   },
   "source": [
    "**Approach 2:** Use the default parameters for CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZdU-JSQNVNQR"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect):\n",
    "    \n",
    "    # create document-term matrices using the vectorizer\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    \n",
    "    # print the number of features that were generated\n",
    "    print('Features: ', X_train_dtm.shape[1])\n",
    "    \n",
    "    # use Multinomial Naive Bayes to predict the star rating\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    \n",
    "    # Get the training accuracy\n",
    "    print('Training Accuracy: ', metrics.accuracy_score(y_train, nb.predict(X_train_dtm)))\n",
    "    # print the accuracy of its predictions\n",
    "    print('Test Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1544276561401,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "-cnkkxwgVNQS",
    "outputId": "59e18627-2df7-4758-c9c2-50c0c5d6c9c1"
   },
   "outputs": [],
   "source": [
    "# use the default parameters\n",
    "vect = CountVectorizer()\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FtoHym8GVNQV"
   },
   "source": [
    "**Approach 3:** Don't convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1544276591482,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "3DCqY-dGVNQW",
    "outputId": "f00bf938-f351-4cd3-b3b6-18710ee9b36a"
   },
   "outputs": [],
   "source": [
    "# don't convert to lowercase\n",
    "vect = CountVectorizer(lowercase=False)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWnn3GylVNQZ"
   },
   "source": [
    "**Approach 4:** Include 1-grams and 2-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2646,
     "status": "ok",
     "timestamp": 1544276599710,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "35a7JQrpVNQb",
    "outputId": "2b4696b0-7725-4a4b-9657-ee9993825bd3"
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why approach 4 achieve the highest training accuracy and the lowest testing accuracy at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJ0ypnd9VNQd"
   },
   "source": [
    "**Summary:** Tuning CountVectorizer is a form of **feature engineering**, the process through which you create features that don't natively exist in the dataset. Your goal is to create features that contain the **signal** from the data (with respect to the response value), rather than the **noise**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgIBuWPYVNQd"
   },
   "source": [
    "## Part 4: Removing frequent terms (stop words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfSgXJJEVNQd"
   },
   "source": [
    "- **What:** Remove common words that appear in most documents\n",
    "- **Why:** They probably don't tell you much about your text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PgXyiLgVNQd",
    "outputId": "6595bb5c-55c2-48ad-df5f-4bc36db2acb1"
   },
   "outputs": [],
   "source": [
    "# show vectorizer parameters\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06eYzBgzVNQg"
   },
   "source": [
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1088,
     "status": "ok",
     "timestamp": 1544276620676,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "viQtQnveVNQg",
    "outputId": "7d3fe9a2-efb4-4546-e6a3-0822a340bc0e"
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w2QgSXPeVNQj",
    "outputId": "3fa60005-fd96-4640-d4d4-e467de8314fe"
   },
   "outputs": [],
   "source": [
    "# examine the stop words\n",
    "print(sorted(vect.get_stop_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouLU0jRNVNQm"
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1196,
     "status": "ok",
     "timestamp": 1544276631355,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "jNyIV2URVNQq",
    "outputId": "c02e9238-8f60-42a0-b6e6-37390bfd1351"
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0OhZ-t0JVNQs"
   },
   "source": [
    "- **stop\\_words\\_:** Terms that were ignored because they either:\n",
    "    - occurred in too many documents (max_df)\n",
    "    - occurred in too few documents (min_df)\n",
    "    - were cut off by feature selection (max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1544276640087,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "pzH98xYRVNQt",
    "outputId": "592bf7ef-95f5-4295-f208-6e9f96124f1e"
   },
   "outputs": [],
   "source": [
    "# examine the terms that were removed due to max_df (\"corpus-specific stop words\")\n",
    "print(vect.stop_words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVGrHZ94VNQy"
   },
   "source": [
    "## Part 5: Removing infrequent terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwDzSbzzVNQz"
   },
   "source": [
    "- **max_features:** int or None, default=None\n",
    "    - If not None, build a vocabulary that only considers the top max_features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1544276667195,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "ABlT1yqMVNQz",
    "outputId": "9788a739-bb8e-4df4-8f83-2699827d023f"
   },
   "outputs": [],
   "source": [
    "# only keep the top 1000 most frequent terms\n",
    "vect = CountVectorizer(max_features=1000)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVQ3A6vcVNQ1"
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1544276672623,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "pg0tHWA2VNQ1",
    "outputId": "2a33a2de-b164-422b-fb4f-91e0d2a006ae"
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2450,
     "status": "ok",
     "timestamp": 1544276680402,
     "user": {
      "displayName": "Yiliang Zhao",
      "photoUrl": "https://lh5.googleusercontent.com/-04VJ4L4y79E/AAAAAAAAAAI/AAAAAAAAAAc/JEDUZ4BZndY/s64/photo.jpg",
      "userId": "06402719980278340331"
     },
     "user_tz": -480
    },
    "id": "jKqMwJJjVNQ3",
    "outputId": "f9b28567-e3d2-43b8-abdf-4fad6b7219e7"
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams, and only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGo-ua7gVNQ7"
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "- **Experiment**, and let the data tell you the best approach!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Natural Language Processing.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
