{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data from TWITTER \n",
    "\n",
    "- https://www.twitter.com/leehsienloong\n",
    "- https://www.twitter.com/STcom\n",
    "- https://www.twitter.com/stompsingapore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Twitter API keys\n",
    "\n",
    "In order to access Twitter Streaming API, we need to get 4 pieces of information from Twitter: API key, API secret, Access token and Access token secret. Follow the steps below to get all 4 elements:\n",
    "\n",
    "- Create a Twitter account if you do not already have one.\n",
    "- Go to https://apps.twitter.com/ and log in with your Twitter credentials.\n",
    "- Click **Create New App**\n",
    "- Fill out the form, agree to the terms, and click **Create your Twitter application**\n",
    "- In the next page, click on **API keys** tab, and copy your **API key** and **API secret**.\n",
    "- Scroll down and click **Create my access token**, and copy your **Access token** and **Access token secret**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to Twitter Streaming API and Download Data using `Tweepy`\n",
    "\n",
    "We will be using a Python library called **Tweepy** to connect to **Twitter Streaming API** and downloading the data. If you don't have Tweepy installed in your machine, go to this link ([github.com/tweepy/tweepy](https://github.com/tweepy/tweepy)), and follow the installation instructions.\n",
    "\n",
    "To install, simply launch **Terminal** and type:\n",
    "- pip install tweepy \n",
    "- **[or]** sudo pip install tweepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that contains the user credentials to access Twitter API \n",
    "access_token =     # PLEASE USE YOUR OWN\n",
    "access_token_secret =   # PLEASE USE YOUR OWN\n",
    "consumer_key =                              # PLEASE USE YOUR OWN\n",
    "consumer_secret = # PLEASE USE YOUR OWN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = api.search(q='obama', count=50, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a result to JSON with \"._json\"\n",
    "print(type(results[0]))\n",
    "print(type(results[0]._json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the results into a `list of dictionaries`\n",
    "list_of_status_dicts = []\n",
    "\n",
    "for result in results:\n",
    "    list_of_status_dicts.append( result._json )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is the same as the code in the cell above, just that it's shorter.\n",
    "# [Python list comprehension] Convert all the results into a `list of dictionaries`\n",
    "list_of_status_dicts = [result._json for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_status_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_status_dicts[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_status_dicts[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_status_dicts[0]['retweet_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Search (Advance)\n",
    "\n",
    "* max_id in the api.search – Returns only statuses with an ID less than (that is, older than) or equal to the specified ID. Therefore, using this argument ```max_id = str(last_id -1)``` can make tweets received currently should be older than the tweeted received before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'trump'\n",
    "max_tweets = 555\n",
    "\n",
    "searched_tweets = []\n",
    "last_id = -1\n",
    "while len(searched_tweets) < max_tweets:\n",
    "    count = max_tweets - len(searched_tweets)\n",
    "    try:\n",
    "        new_tweets = api.search(q=query, lang='en', count=count, max_id=str(last_id - 1))\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "    except tweepy.TweepError as e:\n",
    "        # Depending on TweepError.code, one may want to retry or wait\n",
    "        # to keep things simple, we will give up on an error\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(searched_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all the results into a `list of dictionaries`\n",
    "list_of_status_dicts_2 = [x._json for x in searched_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_status_dicts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_status_dicts_2[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Streaming\n",
    "\n",
    "The Streaming APIs give developers low latency access to Twitter’s global stream of Tweet data. A proper implementation of a streaming client will be pushed messages indicating Tweets and other events have occurred, without any of the overhead associated with polling a REST endpoint.\n",
    "\n",
    "More info: https://dev.twitter.com/streaming/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "\n",
    "# This is a basic listener that just prints received tweets to stdout.\n",
    "class StdOutListener(StreamListener):\n",
    "    ## this class is defined as the listener. \n",
    "    def on_data(self, json_data):\n",
    "        # print(json_data)\n",
    "        filename = re.sub(r'\\s|\\/|:', r'_', '%s.txt' % str(datetime.now()))\n",
    "        fileloc = './twitter_stream_data/' + filename\n",
    "  \n",
    "        # 1% chance of printing out the file location\n",
    "        if random.randint(0, 100) == 0:\n",
    "            print(fileloc)\n",
    "        # End of if statement.\n",
    "            \n",
    "        with open(fileloc, 'w') as f:\n",
    "            f.write(json_data)\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    l = StdOutListener()\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    stream = Stream(auth, l)\n",
    "\n",
    "    # This line filter Twitter Streams to capture data by the keywords: 'obama', 'trump', 'clinton'\n",
    "    stream.filter(track=['obama', 'trump', 'clinton'])\n",
    "\n",
    "\"\"\"\n",
    "Note that this is a while loop! It runs until the cows come home!\n",
    "To terminate this infinite loop, press the stop button in the iPython notebook's TOOLBAR.\n",
    "\n",
    "You will see a \"KeyboardInterrupt\" error message -- which is what you are supposed to get.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You should see the files in the `twitter_stream_data` folder\n",
    "\n",
    "![](./images/twitter_stream_data_folder.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "list_of_files = (glob.glob(\"./twitter_stream_data/*.txt\"))\n",
    "len(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the TXT files into a \"list of dictionary objects\" called \"tweets_data\"\n",
    "import json\n",
    "tweets_data = []\n",
    "\n",
    "for fname in list_of_files:\n",
    "    tweets_file = open(fname, \"r\")\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the number of tweets using the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will structure the tweets data into a pandas DataFrame to simplify the data manipulation. We will start by creating an empty DataFrame called tweets using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add 3 columns to the tweets DataFrame called text, lang, and country. text column contains the tweet, lang column contains the language in which the tweet was written, and country the country from which the tweet was sent.\n",
    "\n",
    "lambda is another way to define function in python such as:\n",
    "\n",
    "square_root = lambda x: math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['text'] = list(map(lambda tweet: tweet['text'] if 'text' in tweet else None, tweets_data))\n",
    "tweets['lang'] = list(map(lambda tweet: tweet['lang'] if 'lang' in tweet else None, tweets_data))\n",
    "tweets['country'] = list(map(lambda tweet: tweet['place']['country'] if ('place' in tweet and (tweet['place'] != None)) else None, tweets_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the **tweets** DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[  tweets['country'].notnull()  ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 languages and Top 5 countries\n",
    "\n",
    "Next, we will create 2 charts: The first one describing the Top 5 languages in which the tweets were written, and the second the Top 5 countries from which the tweets were sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "tweets_by_lang = tweets['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Languages', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
    "tweets_by_lang[:5].plot(ax=ax, kind='bar', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Countries', fontsize=15)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=15)\n",
    "ax.set_title('Top 5 countries', fontsize=15, fontweight='bold')\n",
    "tweets_by_country[:5].plot(ax=ax, kind='bar', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mining the Tweets\n",
    "\n",
    "Our main goals in these text mining tasks are: compare the popularity of Obama, Trump and Clinton and to retrieve links. We will do the following steps:\n",
    "\n",
    "- We will add tags to our tweets DataFrame in order to be able to manipualte the data easily.\n",
    "- Extract links from tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a function that checks if a specific keyword is present in a text. We will do this by using regular expressions. Python provides a library for regular expression called re. We will start by importing this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a function called word_in_text(word, text). This function return True if a word is found in text, otherwise it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_in_text(word, text):\n",
    "    if word and text:\n",
    "        word = word.lower()\n",
    "        text = text.lower()\n",
    "        match = re.search(word, text)\n",
    "        if match:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add 3 columns to our tweets DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['obama'] = tweets['text'].apply(lambda tweet: word_in_text('obama', tweet))\n",
    "tweets['trump'] = tweets['text'].apply(lambda tweet: word_in_text('trump', tweet))\n",
    "tweets['clinton'] = tweets['text'].apply(lambda tweet: word_in_text('clinton', tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified DataFrame looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the number of tweets for each person as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets['obama'].value_counts()[True])\n",
    "print(tweets['trump'].value_counts()[True])\n",
    "print(tweets['clinton'].value_counts()[True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a simple comparaison chart by executing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = ['obama', 'trump', 'clinton']\n",
    "tweets_by_politicians = [tweets['obama'].value_counts()[True], tweets['trump'].value_counts()[True], tweets['clinton'].value_counts()[True]]\n",
    "\n",
    "x_pos = list(range(len(politicians)))\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by_politicians, width, alpha=1, color='g')\n",
    "\n",
    "# Setting axis labels and ticks\n",
    "ax.set_ylabel('Number of tweets', fontsize=15)\n",
    "ax.set_title('Ranking: Obama vs. Trump vs. Clinton', fontsize=10, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(politicians)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting links from the tweets\n",
    "\n",
    "Now, we want to retrieve links in the tweets. We will start by creating a function that uses regular expressions for retrieving link that start with **\"http://\"** or **\"https://\"** from a text. This function will return the url if found, otherwise it returns an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    try:\n",
    "        regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "        match = re.search(regex, text)\n",
    "        if match:\n",
    "            return match.group()\n",
    "        return ''\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add a column called link to our tweets DataFrame. This column will contain the urls information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified DataFrame looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a new DataFrame called **tweets_with_link**. \n",
    "This DataFrame is a subset of tweets DataFrame and contains all tweets that have a link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_link = tweets[ tweets['link'] != ''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_link.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_link.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out all links for **obama**, **trump**, and **clinton** by executing the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_with_link[tweets_with_link['obama']   == True]['link'])\n",
    "print(tweets_with_link[tweets_with_link['trump']   == True]['link'])\n",
    "print(tweets_with_link[tweets_with_link['clinton'] == True]['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now say we want to read one of the links above, https://t.co/oua32nXu8W\n",
    "\n",
    "# Read the HTML source of the URL: https://t.co/oua32nXu8W\n",
    "import urllib.request\n",
    "url = 'https://t.co/oua32nXu8W'\n",
    "request = urllib.request.Request(url)\n",
    "response = urllib.request.urlopen(request)\n",
    "html = response.read()\n",
    "try:\n",
    "    html = html.decode('utf-8')\n",
    "except:\n",
    "    html = html.decode('unicode_escape')\n",
    "\n",
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Man Charged for Threatening to Kill Trump Is Clinton 'Close Family Friend'</title>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the title of the HTML document\n",
    "\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo by Wendy Maeda/The Boston Globe via Getty Images\n",
      "The Florida man who was arrested on Tuesday for threatening the life of President-elect Donald Trump on Twitter is a close family friend of former President Bill Clinton and his wife, Hillary Clinton.\n",
      "Hillary Clinton gave the eulogy of Puopolo's mother, Sonia, who died during the attack on the World Trade Center on September 11, 2001.\n",
      "Clinton referred to him as \"Dom Jr.'s latest computer wizardry\" during the speech about his mother.\n",
      "He has also given $20,000 to the Democratic National Committee.\n",
      "Puopolo Jr. is currently being held without bail for a tweet where he said he was going to show up at the inauguration and assassinate the president-elect.\n",
      "The tweet said, \"This is the 16th of January 2017, I will be at the review/ inauguration and I will kill President Trump, President elect Trump today.\"\n",
      "The family ties stretch from Puopolo Jr. to his sister, Sonia Tita Puopolo.\n",
      "Hillary Rodman Clinton sits with the Puopolo family during a memorial service for Democratic activist Sonia Puopolo. Puopolo's husband Dominic and Dominic, Jr. are at the top. Photo by Wendy Maeda/The Boston Globe via Getty Images\n",
      "Her Facebook page contains photos of her and Hillary.\n"
     ]
    }
   ],
   "source": [
    "# Extract all the paragraphs (p) and print out the content\n",
    "\n",
    "for paragraph in soup.find_all('p'):\n",
    "    if paragraph.string is not None:\n",
    "        print(paragraph.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial, we covered many techniques used in text mining. The code here can be:\n",
    "1. modified to create a deeper analysis, or  \n",
    "2. adapted to another use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- http://en.wikipedia.org/wiki/Text_mining\n",
    "- http://en.wikipedia.org/wiki/Word-sense_disambiguation\n",
    "- http://en.wikipedia.org/wiki/Regular_expression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
