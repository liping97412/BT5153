{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "Recap Last Week:\n",
    "1. Reading in the Kaggle data and adding features\n",
    "2. Using a **`Pipeline`** for proper cross-validation\n",
    "\n",
    "This Week:\n",
    "3. Combining **`GridSearchCV`** with **`Pipeline`**\n",
    "4. Efficiently searching for tuning parameters using **`RandomizedSearchCV`**\n",
    "5. Adding features to a document-term matrix (using SciPy)\n",
    "6. Adding features to a document-term matrix (using **`FeatureUnion`**)\n",
    "7. Ensembling models\n",
    "8. Locating groups of similar cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Kaggle data and adding features\n",
    "\n",
    "- Our goal is to predict the **cuisine** of a recipe, given its **ingredients**.\n",
    "- **Feature engineering** is the process through which you create features that don't natively exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame and adds new features\n",
    "def make_features(df):\n",
    "    \n",
    "    # number of ingredients\n",
    "    df['num_ingredients'] = df.ingredients.apply(len)\n",
    "    \n",
    "    # mean length of ingredient names\n",
    "    df['ingredient_length'] = df.ingredients.apply(lambda x: np.mean([len(item) for item in x]))\n",
    "    \n",
    "    # string representation of the ingredient list\n",
    "    df['ingredients_str'] = df.ingredients.astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same features in the training data and the new data\n",
    "train = make_features(pd.read_json('week6_train.json'))\n",
    "new = make_features(pd.read_json('week6_test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>['baking powder', 'eggs', 'all-purpose flour',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>['sugar', 'egg yolks', 'corn starch', 'cream o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>['sausage links', 'fennel bulb', 'fronds', 'ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['meat cuts', 'file powder', 'smoked sausage',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>['ground black pepper', 'salt', 'sausage casin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \n",
       "0           9.333333  ['baking powder', 'eggs', 'all-purpose flour',...  \n",
       "1          10.272727  ['sugar', 'egg yolks', 'corn starch', 'cream o...  \n",
       "2           9.666667  ['sausage links', 'fennel bulb', 'fronds', 'ol...  \n",
       "3          12.000000  ['meat cuts', 'file powder', 'smoked sausage',...  \n",
       "4          13.000000  ['ground black pepper', 'salt', 'sausage casin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using a `Pipeline` for proper cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = train.ingredients_str\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is just a Series of strings\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the regex pattern that is used for tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate Multinomial Naive Bayes (with the default parameters)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline of vectorization and Naive Bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "          vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proper cross-validation:**\n",
    "\n",
    "- By passing our pipeline to **`cross_val_score`**, features will be created from **`X`** (via **`CountVectorizer`**) within each fold of cross-validation.\n",
    "- This process simulates the real world, in which your out-of-sample data will contain **features that were not seen** during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7322884933790151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining `GridSearchCV` with `Pipeline`\n",
    "\n",
    "- We use **`GridSearchCV`** to locate optimal tuning parameters by performing an \"exhaustive grid search\" of different parameter combinations, searching for the combination that has the best cross-validated accuracy.\n",
    "- By passing a **`Pipeline`** to **`GridSearchCV`** (instead of just a model), we can search tuning parameters for both the vectorizer and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['countvectorizer', 'multinomialnb'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pipeline (instead of the model) to GridSearchCV\n",
    "#gridsearch will try all the combinations of parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 36.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), p...  vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the grid search\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.10126305, 1.07746267, 0.67563872, 0.6772387 ]),\n",
       " 'std_fit_time': array([0.05272655, 0.05705806, 0.00458731, 0.00708272]),\n",
       " 'mean_score_time': array([0.22781305, 0.20441165, 0.11600661, 0.11520667]),\n",
       " 'std_score_time': array([0.03414505, 0.00344112, 0.00303332, 0.00097987]),\n",
       " 'param_countvectorizer__token_pattern': masked_array(data=['\\\\b\\\\w\\\\w+\\\\b', '\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\",\n",
       "                    \"'([a-z ]+)'\"],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_multinomialnb__alpha': masked_array(data=[0.5, 1, 0.5, 1],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 0.5},\n",
       "  {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 1},\n",
       "  {'countvectorizer__token_pattern': \"'([a-z ]+)'\",\n",
       "   'multinomialnb__alpha': 0.5},\n",
       "  {'countvectorizer__token_pattern': \"'([a-z ]+)'\",\n",
       "   'multinomialnb__alpha': 1}],\n",
       " 'split0_test_score': array([0.720422  , 0.72079879, 0.74328058, 0.72619945]),\n",
       " 'split1_test_score': array([0.73133953, 0.73159085, 0.75596884, 0.74114099]),\n",
       " 'split2_test_score': array([0.72134238, 0.71933132, 0.74509804, 0.72674711]),\n",
       " 'split3_test_score': array([0.72003522, 0.72028676, 0.74481197, 0.73261225]),\n",
       " 'split4_test_score': array([0.72769599, 0.72643765, 0.74933937, 0.73474267]),\n",
       " 'mean_test_score': array([0.72416654, 0.72368884, 0.7476995 , 0.73228742]),\n",
       " 'std_test_score': array([0.00453846, 0.00466765, 0.00459876, 0.00551981]),\n",
       " 'rank_test_score': array([3, 4, 1, 2]),\n",
       " 'split0_train_score': array([0.75150886, 0.74710801, 0.79734063, 0.77131271]),\n",
       " 'split1_train_score': array([0.74927709, 0.74387101, 0.79368871, 0.76763264]),\n",
       " 'split2_train_score': array([0.75089572, 0.74596141, 0.79675027, 0.76950154]),\n",
       " 'split3_train_score': array([0.75109198, 0.74675549, 0.79879333, 0.77198881]),\n",
       " 'split4_train_score': array([0.75084048, 0.74527917, 0.79624218, 0.7687498 ]),\n",
       " 'mean_train_score': array([0.75072283, 0.74579502, 0.79656302, 0.7698371 ]),\n",
       " 'std_train_score': array([0.00076   , 0.00115257, 0.00167204, 0.00161008])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the score for each combination of parameters\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7476995021873586\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Efficiently searching for tuning parameters using `RandomizedSearchCV`\n",
    "\n",
    "- When there are many parameters to tune, searching all possible combinations of parameter values may be **computationally infeasible**.\n",
    "- **`RandomizedSearchCV`** searches a sample of the parameter values, and you control the computational \"budget\".\n",
    "\n",
    "[RandomizedSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats documentation](http://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'countvectorizer__min_df': [1, 2, 3],\n",
       " 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen at 0x18124048>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for any continuous parameters, specify a distribution instead of a list of options\n",
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3]\n",
    "param_grid['multinomialnb__alpha'] = sp.stats.uniform(scale=1)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed for sp.stats.uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters are n_iter (number of searches) and random_state\n",
    "rand = RandomizedSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_iter=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), p...  vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "          fit_params=None, iid='warn', n_iter=5, n_jobs=None,\n",
       "          param_distributions={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'countvectorizer__min_df': [1, 2, 3], 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000000018124048>},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the randomized search\n",
    "%time rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.67103834, 0.66823826, 1.02965889, 1.0352591 , 1.04926004]),\n",
       " 'std_fit_time': array([0.00729429, 0.00696879, 0.00355552, 0.0029259 , 0.01907357]),\n",
       " 'mean_score_time': array([0.11500659, 0.11280642, 0.20581183, 0.20341172, 0.21841245]),\n",
       " 'std_score_time': array([0.00219101, 0.00240015, 0.00222721, 0.00233246, 0.02050088]),\n",
       " 'param_countvectorizer__min_df': masked_array(data=[2, 2, 1, 2, 3],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_countvectorizer__token_pattern': masked_array(data=[\"'([a-z ]+)'\", \"'([a-z ]+)'\", '\\\\b\\\\w\\\\w+\\\\b',\n",
       "                    '\\\\b\\\\w\\\\w+\\\\b', '\\\\b\\\\w\\\\w+\\\\b'],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_multinomialnb__alpha': masked_array(data=[0.7203244934421581, 0.9990405153241447,\n",
       "                    0.3965807272960261, 0.39676747423066994,\n",
       "                    0.4191945144032948],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'countvectorizer__min_df': 2,\n",
       "   'countvectorizer__token_pattern': \"'([a-z ]+)'\",\n",
       "   'multinomialnb__alpha': 0.7203244934421581},\n",
       "  {'countvectorizer__min_df': 2,\n",
       "   'countvectorizer__token_pattern': \"'([a-z ]+)'\",\n",
       "   'multinomialnb__alpha': 0.9990405153241447},\n",
       "  {'countvectorizer__min_df': 1,\n",
       "   'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 0.3965807272960261},\n",
       "  {'countvectorizer__min_df': 2,\n",
       "   'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 0.39676747423066994},\n",
       "  {'countvectorizer__min_df': 3,\n",
       "   'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 0.4191945144032948}],\n",
       " 'split0_test_score': array([0.74064305, 0.73122331, 0.71991962, 0.71841246, 0.71778448]),\n",
       " 'split1_test_score': array([0.75458658, 0.74754964, 0.73159085, 0.72945464, 0.72857502]),\n",
       " 'split2_test_score': array([0.7428356 , 0.73629965, 0.72134238, 0.71870287, 0.71794872]),\n",
       " 'split3_test_score': array([0.74242234, 0.73751729, 0.71915482, 0.71739404, 0.71588479]),\n",
       " 'split4_test_score': array([0.74669687, 0.73851768, 0.72543098, 0.72341764, 0.72329181]),\n",
       " 'mean_test_score': array([0.74543672, 0.73822095, 0.72348771, 0.72147634, 0.72069694]),\n",
       " 'std_test_score': array([0.00498376, 0.00529803, 0.00459501, 0.00449867, 0.0046477 ]),\n",
       " 'rank_test_score': array([1, 2, 3, 4, 5]),\n",
       " 'split0_train_score': array([0.78951339, 0.77851125, 0.75264051, 0.75015717, 0.74783101]),\n",
       " 'split1_train_score': array([0.78554815, 0.77479884, 0.75003143, 0.7468255 , 0.7451911 ]),\n",
       " 'split2_train_score': array([0.78835879, 0.77673015, 0.75209001, 0.74935571, 0.74778427]),\n",
       " 'split3_train_score': array([0.79103164, 0.77968765, 0.7524432 , 0.74970933, 0.74779248]),\n",
       " 'split4_train_score': array([0.78753888, 0.77698181, 0.75225438, 0.74945801, 0.74713294]),\n",
       " 'mean_train_score': array([0.78839817, 0.77734194, 0.75189191, 0.74910114, 0.74714636]),\n",
       " 'std_train_score': array([0.00184615, 0.00166379, 0.0009483 , 0.00117097, 0.00101157])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745436717453613\n",
      "{'countvectorizer__min_df': 2, 'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.7203244934421581}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.7203244934421581, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['southern_us', 'southern_us', 'italian', ..., 'italian',\n",
       "       'southern_us', 'mexican'], dtype='<U12')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV/GridSearchCV automatically refit the best model with the entire dataset, and can be used to make predictions\n",
    "new_pred_class_rand = rand.predict(X_new)\n",
    "new_pred_class_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75342)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class_rand}).set_index('id').to_csv('sub3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding features to a document-term matrix (using SciPy)\n",
    "\n",
    "- So far, we've trained models on either the **document-term matrix** or the **manually created features**, but not both.\n",
    "- To train a model on both types of features, we need to **combine them into a single feature matrix**.\n",
    "- Because one of the matrices is **sparse** and the other is **dense**, the easiest way to combine them is by using SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.sparse documentation](http://docs.scipy.org/doc/scipy/reference/sparse.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of the manually created features\n",
    "X_manual = train.loc[:, ['num_ingredients', 'ingredient_length']]\n",
    "X_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sparse matrix from the DataFrame\n",
    "X_manual_sparse = sp.sparse.csr_matrix(X_manual)\n",
    "type(X_manual_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two sparse matrices\n",
    "X_dtm_manual = sp.sparse.hstack([X_dtm, X_manual_sparse])\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This was a relatively easy process.\n",
    "- However, it does not allow us to do **proper cross-validation**, and it doesn't integrate well with the rest of the **scikit-learn workflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Adding features to a document-term matrix (using `FeatureUnion`)\n",
    "\n",
    "- Below is an alternative process that does allow for proper cross-validation, and does integrate well with the scikit-learn workflow.\n",
    "- To use this process, we have to learn about transformers, **`FunctionTransformer`**, and **`FeatureUnion`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are \"transformers\"?\n",
    "\n",
    "Transformer objects provide a `transform` method in order to perform **data transformations**. Here are a few examples:\n",
    "\n",
    "- **`CountVectorizer`**\n",
    "    - `fit` learns the vocabulary\n",
    "    - `transform` creates a document-term matrix using the vocabulary\n",
    "- **`Imputer`**\n",
    "    - `fit` learns the value to impute\n",
    "    - `transform` fills in missing entries using the imputation value\n",
    "- **`StandardScaler`**\n",
    "    - `fit` learns the mean and scale of each feature\n",
    "    - `transform` standardizes the features using the mean and scale\n",
    "- **`HashingVectorizer`**\n",
    "    - `fit` is not used, and thus it is known as a \"stateless\" transformer\n",
    "    - `transform` creates the document-term matrix using a hash of the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a function into a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the manually created features\n",
    "def get_manual(df):\n",
    "    return df.loc[:, ['num_ingredients', 'ingredient_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_manual(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FunctionTransformer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) (new in 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._function_transformer.FunctionTransformer"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to make the transformer function to be accpted by the sklearn module\n",
    "# create a stateless transformer from the get_manual function\n",
    "get_manual_ft = FunctionTransformer(get_manual, validate=False)\n",
    "type(get_manual_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function using the transform method\n",
    "get_manual_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the ingredients string\n",
    "def get_text(df):\n",
    "    return df.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and test another transformer\n",
    "get_text_ft = FunctionTransformer(get_text, validate=False)\n",
    "get_text_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining feature extraction steps\n",
    "\n",
    "- **`FeatureUnion`** applies a list of transformers in parallel to the input data (not sequentially), then **concatenates the results**.\n",
    "- This is useful for combining several feature extraction mechanisms into a single transformer.\n",
    "\n",
    "![Pipeline versus FeatureUnion](pipeline_versus_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_union documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is identical to a FeatureUnion with just one transformer\n",
    "union = make_union(vect)\n",
    "X_dtm = union.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to add a second transformer to the Feature Union (what's wrong with this?) the ingredient column is a list, not a string\n",
    "# union = make_union(vect, get_manual_ft)\n",
    "# X_dtm_manual = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly combine the transformers into a FeatureUnion\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "X_dtm_manual = union.fit_transform(train)\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline in a FeatureUnion](pipeline_in_a_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102895106852953"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly improper cross-validation\n",
    "cross_val_score(nb, X_dtm_manual, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline of the FeatureUnion and Naive Bayes\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134318388611878"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly cross-validate the entire pipeline (and pass it the entire DataFrame)\n",
    "cross_val_score(pipe, train, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to specify `Pipeline` and `FeatureUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder of how we created the pipeline\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [FeatureUnion documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the pipeline structure without using make_pipeline or make_union\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "pipe = Pipeline([\n",
    "    ('featureunion', FeatureUnion([\n",
    "            ('pipeline', Pipeline([\n",
    "                    ('functiontransformer', get_text_ft),\n",
    "                    ('countvectorizer', vect)\n",
    "                    ])),\n",
    "            ('functiontransformer', get_manual_ft)\n",
    "        ])),\n",
    "    ('multinomialnb', nb)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search of a nested `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('featureunion', FeatureUnion(n_jobs=None,\n",
       "         transformer_list=[('pipeline', Pipeline(memory=None,\n",
       "       steps=[('functiontransformer', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "            func=<function get_text at 0x00000000162519D8>, inv_kw_args=None,\n",
       "            inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "            ... inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "            pass_y='deprecated', validate=False))],\n",
       "         transformer_weights=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "  \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['featureunion__pipeline__countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('featureunion', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('pipeline', Pipeline(memory=None,\n",
       "     steps=[('functiontransformer', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "          func=<function get_text at 0x00000000162519D8>, inv_kw_args=None,\n",
       "          inverse...ormer_weights=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"], 'multinomialnb__alpha': [0.5, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426710916679238\n",
      "{'featureunion__pipeline__countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Ensembling models\n",
    "\n",
    "Rather than combining features into a single feature matrix and training a single model, we can instead create separate models and \"ensemble\" them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is ensembling?\n",
    "\n",
    "Ensemble learning (or \"ensembling\") is the process of combining several predictive models in order to produce a combined model that is **better than any individual model**.\n",
    "\n",
    "- **Regression:** average the predictions made by the individual models\n",
    "- **Classification:** let the models \"vote\" and use the most common prediction, or average the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different \"processes\", such as:\n",
    "    - different types of models\n",
    "    - different features\n",
    "    - different tuning parameters\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "**Note:** There are also models that have built-in ensembling, such as Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: KNN model using only manually created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['num_ingredients', 'ingredient_length']\n",
    "X = train[feature_cols]\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KNN with K=800\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=800, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train KNN on all of the training data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X_new as the manually created features\n",
    "X_new = new[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_knn = knn.predict_proba(X_new)\n",
    "new_pred_prob_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02625, 0.0275 , 0.01375, 0.04375, 0.03375, 0.08   , 0.0175 ,\n",
       "       0.075  , 0.0275 , 0.135  , 0.01   , 0.075  , 0.01875, 0.165  ,\n",
       "       0.00875, 0.0125 , 0.1525 , 0.025  , 0.0275 , 0.025  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_knn[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1b42fec8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display classes with probabilities\n",
    "zip(knn.classes_, new_pred_prob_knn[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilities will sum to 1 for each row\n",
    "new_pred_prob_knn[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Naive Bayes model using only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.7203244934421581, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_rand = rand.predict_proba(X_new)\n",
    "new_pred_prob_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.59476986e-04, 4.04209227e-01, 7.38375500e-05, 1.29657196e-04,\n",
       "       3.00331358e-03, 2.09215451e-03, 4.82924358e-04, 5.35343905e-04,\n",
       "       1.22359513e-01, 7.08319855e-03, 2.06222706e-04, 7.18742744e-04,\n",
       "       5.49904762e-06, 1.64352345e-03, 1.01157435e-05, 1.71202022e-02,\n",
       "       4.39643190e-01, 3.21357119e-04, 1.84691815e-06, 6.53184216e-07])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_rand[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling models 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01330474, 0.21585461, 0.00691192, 0.02193983, 0.01837666,\n",
       "       0.04104608, 0.00899146, 0.03776767, 0.07492976, 0.0710416 ,\n",
       "       0.00510311, 0.03785937, 0.00937775, 0.08332176, 0.00438006,\n",
       "       0.0148101 , 0.2960716 , 0.01266068, 0.01375092, 0.01250033])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for the first row\n",
    "(new_pred_prob_knn[0, :] + new_pred_prob_rand[0, :]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.215855</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.041046</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.037768</td>\n",
       "      <td>0.074930</td>\n",
       "      <td>0.071042</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.083322</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>0.296072</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.018143</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>0.546973</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.013125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013627</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>0.045080</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.449318</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>0.080644</td>\n",
       "      <td>0.024697</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.079388</td>\n",
       "      <td>0.112301</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.012510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.010223</td>\n",
       "      <td>0.019458</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.045985</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.081880</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.072109</td>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brazilian   british  cajun_creole   chinese  filipino    french     greek  \\\n",
       "0   0.013305  0.215855      0.006912  0.021940  0.018377  0.041046  0.008991   \n",
       "1   0.008752  0.011794      0.016875  0.045000  0.018143  0.024328  0.015625   \n",
       "2   0.013627  0.009447      0.007219  0.020000  0.015059  0.045080  0.011783   \n",
       "3   0.003125  0.004375      0.533750  0.038750  0.001875  0.023125  0.006250   \n",
       "4   0.001877  0.010223      0.019458  0.020625  0.003751  0.045985  0.016877   \n",
       "\n",
       "     indian     irish   italian  jamaican  japanese    korean   mexican  \\\n",
       "0  0.037768  0.074930  0.071042  0.005103  0.037859  0.009378  0.083322   \n",
       "1  0.046250  0.010630  0.070625  0.005626  0.027503  0.021875  0.066875   \n",
       "2  0.029383  0.013628  0.449318  0.005651  0.038760  0.007505  0.080644   \n",
       "3  0.075625  0.001250  0.051875  0.011875  0.008125  0.003125  0.107500   \n",
       "4  0.013750  0.012539  0.643956  0.003129  0.007500  0.003750  0.081880   \n",
       "\n",
       "   moroccan   russian  southern_us   spanish      thai  vietnamese  \n",
       "0  0.004380  0.014810     0.296072  0.012661  0.013751    0.012500  \n",
       "1  0.008125  0.008751     0.546973  0.007500  0.025625    0.013125  \n",
       "2  0.024697  0.008373     0.079388  0.112301  0.015626    0.012510  \n",
       "3  0.029375  0.001875     0.025000  0.007500  0.038125    0.027500  \n",
       "4  0.004377  0.003133     0.072109  0.017581  0.014375    0.003125  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for all rows\n",
    "new_pred_prob = pd.DataFrame((new_pred_prob_knn + new_pred_prob_rand) / 2, columns=knn.classes_)\n",
    "new_pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\core\\fromnumeric.py:51: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     southern_us\n",
       "1     southern_us\n",
       "2         italian\n",
       "3    cajun_creole\n",
       "4         italian\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row, find the column with the highest predicted probability\n",
    "new_pred_class = new_pred_prob.apply(np.argmax, axis=1)\n",
    "new_pred_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75241)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class}).set_index('id').to_csv('sub4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** [VotingClassifier](http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier) (new in 0.17) makes it easier to ensemble classifiers, though it is limited to the case in which all of the classifiers are fit to the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Locating groups of similar cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "brazilian       ['ice cubes', 'club soda', 'white rum', 'lime'...\n",
       "british         ['greek yogurt', 'lemon curd', 'confectioners ...\n",
       "cajun_creole    ['herbs', 'lemon juice', 'fresh tomatoes', 'pa...\n",
       "chinese         ['low sodium soy sauce', 'fresh ginger', 'dry ...\n",
       "filipino        ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "french          ['sugar', 'salt', 'fennel bulb', 'water', 'lem...\n",
       "greek           ['romaine lettuce', 'black olives', 'grape tom...\n",
       "indian          ['water', 'vegetable oil', 'wheat', 'salt']['b...\n",
       "irish           ['cooking spray', 'salt', 'black pepper', 'yuk...\n",
       "italian         ['sugar', 'pistachio nuts', 'white almond bark...\n",
       "jamaican        ['plain flour', 'sugar', 'butter', 'eggs', 'fr...\n",
       "japanese        ['sirloin', 'mirin', 'yellow onion', 'low sodi...\n",
       "korean          ['jasmine rice', 'garlic', 'scallions', 'sugar...\n",
       "mexican         ['olive oil', 'purple onion', 'fresh pineapple...\n",
       "moroccan        ['ground cloves', 'whole nutmegs', 'ground gin...\n",
       "russian         ['water', 'grits', 'mozzarella cheese', 'salt'...\n",
       "southern_us     ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "spanish         ['olive oil', 'salt', 'medium shrimp', 'pepper...\n",
       "thai            ['sugar', 'hot chili', 'asian fish sauce', 'li...\n",
       "vietnamese      ['soy sauce', 'vegetable oil', 'red bell peppe...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each cuisine, combine all of the recipes into a single string\n",
    "cuisine_ingredients = train.groupby('cuisine').ingredients_str.sum()\n",
    "cuisine_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['ice cubes', 'club soda', 'white rum', 'lime', 'turbinado']['eggs', 'hearts of palm', 'cilantro', 'coconut cream', 'flax seed meal', 'kosher salt', 'jalapeno chilies', 'garlic', 'cream cheese, soften', 'coconut oil', 'lime juice', 'crushed red pepper flakes', 'ground coriander', 'pepper', 'chicken breasts', 'coconut flour', 'onions']['sweetened condensed milk', 'butter', 'cocoa powder']['lime', 'crushed ice', 'simple syrup', 'cachaca']['sugar', 'corn starch', 'egg whites', 'boiling water', 'col\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the brazilian ingredients\n",
    "cuisine_ingredients['brazilian'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     ['ice cubes', 'club soda', 'white rum', 'lime'...\n",
       "380    ['eggs', 'hearts of palm', 'cilantro', 'coconu...\n",
       "423    ['sweetened condensed milk', 'butter', 'cocoa ...\n",
       "509    ['lime', 'crushed ice', 'simple syrup', 'cacha...\n",
       "724    ['sugar', 'corn starch', 'egg whites', 'boilin...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that they match the brazilian recipes\n",
    "train.loc[train.cuisine=='brazilian', 'ingredients_str'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3040)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from cuisine_ingredients\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "cuisine_dtm = vect.fit_transform(cuisine_ingredients)\n",
    "cuisine_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to calculate document similarity](http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity/12128777#12128777) (Stack Overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between each cuisine and all other cuisines\n",
    "from sklearn import metrics\n",
    "cuisine_similarity = []\n",
    "for idx in range(cuisine_dtm.shape[0]):\n",
    "    similarity = metrics.pairwise.linear_kernel(cuisine_dtm[idx, :], cuisine_dtm).flatten()\n",
    "    cuisine_similarity.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cuisine</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.742318</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.695691</td>\n",
       "      <td>0.687271</td>\n",
       "      <td>0.665712</td>\n",
       "      <td>0.740536</td>\n",
       "      <td>0.778319</td>\n",
       "      <td>0.555604</td>\n",
       "      <td>0.571440</td>\n",
       "      <td>0.743743</td>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.706079</td>\n",
       "      <td>0.743158</td>\n",
       "      <td>0.807694</td>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.653801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.660232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591218</td>\n",
       "      <td>0.467640</td>\n",
       "      <td>0.631355</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.562750</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.926681</td>\n",
       "      <td>0.632625</td>\n",
       "      <td>0.662056</td>\n",
       "      <td>0.508299</td>\n",
       "      <td>0.447177</td>\n",
       "      <td>0.560464</td>\n",
       "      <td>0.543260</td>\n",
       "      <td>0.909540</td>\n",
       "      <td>0.911273</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.478901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.742318</td>\n",
       "      <td>0.591218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605572</td>\n",
       "      <td>0.746146</td>\n",
       "      <td>0.708829</td>\n",
       "      <td>0.688392</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>0.635178</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.532385</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.649837</td>\n",
       "      <td>0.657783</td>\n",
       "      <td>0.747477</td>\n",
       "      <td>0.803624</td>\n",
       "      <td>0.590105</td>\n",
       "      <td>0.605224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.467640</td>\n",
       "      <td>0.605572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.496088</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>0.460745</td>\n",
       "      <td>0.555511</td>\n",
       "      <td>0.635951</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.561849</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.521838</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.817004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.631355</td>\n",
       "      <td>0.746146</td>\n",
       "      <td>0.839802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682939</td>\n",
       "      <td>0.607435</td>\n",
       "      <td>0.655934</td>\n",
       "      <td>0.641009</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.792722</td>\n",
       "      <td>0.748561</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.678316</td>\n",
       "      <td>0.614984</td>\n",
       "      <td>0.696994</td>\n",
       "      <td>0.720370</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.741511</td>\n",
       "      <td>0.806833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.708829</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.682939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759935</td>\n",
       "      <td>0.624868</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.835281</td>\n",
       "      <td>0.723224</td>\n",
       "      <td>0.540283</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>0.666848</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.881162</td>\n",
       "      <td>0.862063</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.548375</td>\n",
       "      <td>0.570924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.695691</td>\n",
       "      <td>0.562750</td>\n",
       "      <td>0.688392</td>\n",
       "      <td>0.496088</td>\n",
       "      <td>0.607435</td>\n",
       "      <td>0.759935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640296</td>\n",
       "      <td>0.583670</td>\n",
       "      <td>0.859279</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.479834</td>\n",
       "      <td>0.696644</td>\n",
       "      <td>0.769411</td>\n",
       "      <td>0.649521</td>\n",
       "      <td>0.641219</td>\n",
       "      <td>0.837447</td>\n",
       "      <td>0.519003</td>\n",
       "      <td>0.538682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.687271</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.618959</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>0.655934</td>\n",
       "      <td>0.624868</td>\n",
       "      <td>0.640296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577336</td>\n",
       "      <td>0.616218</td>\n",
       "      <td>0.734926</td>\n",
       "      <td>0.567997</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.708641</td>\n",
       "      <td>0.795271</td>\n",
       "      <td>0.607425</td>\n",
       "      <td>0.617279</td>\n",
       "      <td>0.678865</td>\n",
       "      <td>0.627460</td>\n",
       "      <td>0.605162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.665712</td>\n",
       "      <td>0.926681</td>\n",
       "      <td>0.635178</td>\n",
       "      <td>0.460745</td>\n",
       "      <td>0.641009</td>\n",
       "      <td>0.837383</td>\n",
       "      <td>0.583670</td>\n",
       "      <td>0.577336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649883</td>\n",
       "      <td>0.680913</td>\n",
       "      <td>0.494765</td>\n",
       "      <td>0.458797</td>\n",
       "      <td>0.591736</td>\n",
       "      <td>0.563302</td>\n",
       "      <td>0.892417</td>\n",
       "      <td>0.902851</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.449931</td>\n",
       "      <td>0.481711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.740536</td>\n",
       "      <td>0.632625</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.555511</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.835281</td>\n",
       "      <td>0.859279</td>\n",
       "      <td>0.616218</td>\n",
       "      <td>0.649883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.510289</td>\n",
       "      <td>0.522574</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.709835</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.718953</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.555095</td>\n",
       "      <td>0.571102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>0.778319</td>\n",
       "      <td>0.662056</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.635951</td>\n",
       "      <td>0.792722</td>\n",
       "      <td>0.723224</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.734926</td>\n",
       "      <td>0.680913</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584691</td>\n",
       "      <td>0.609202</td>\n",
       "      <td>0.731874</td>\n",
       "      <td>0.757461</td>\n",
       "      <td>0.684472</td>\n",
       "      <td>0.752863</td>\n",
       "      <td>0.751671</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.664174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.555604</td>\n",
       "      <td>0.508299</td>\n",
       "      <td>0.532385</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.748561</td>\n",
       "      <td>0.540283</td>\n",
       "      <td>0.469467</td>\n",
       "      <td>0.567997</td>\n",
       "      <td>0.494765</td>\n",
       "      <td>0.510289</td>\n",
       "      <td>0.584691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819832</td>\n",
       "      <td>0.506555</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>0.557271</td>\n",
       "      <td>0.554026</td>\n",
       "      <td>0.547340</td>\n",
       "      <td>0.682606</td>\n",
       "      <td>0.738415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.571440</td>\n",
       "      <td>0.447177</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>0.479834</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.458797</td>\n",
       "      <td>0.522574</td>\n",
       "      <td>0.609202</td>\n",
       "      <td>0.819832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516476</td>\n",
       "      <td>0.477963</td>\n",
       "      <td>0.517675</td>\n",
       "      <td>0.516812</td>\n",
       "      <td>0.582969</td>\n",
       "      <td>0.671054</td>\n",
       "      <td>0.747119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>0.743743</td>\n",
       "      <td>0.560464</td>\n",
       "      <td>0.724866</td>\n",
       "      <td>0.561849</td>\n",
       "      <td>0.678316</td>\n",
       "      <td>0.666848</td>\n",
       "      <td>0.696644</td>\n",
       "      <td>0.708641</td>\n",
       "      <td>0.591736</td>\n",
       "      <td>0.733982</td>\n",
       "      <td>0.731874</td>\n",
       "      <td>0.506555</td>\n",
       "      <td>0.516476</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697460</td>\n",
       "      <td>0.630551</td>\n",
       "      <td>0.691407</td>\n",
       "      <td>0.739875</td>\n",
       "      <td>0.617638</td>\n",
       "      <td>0.623549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.543260</td>\n",
       "      <td>0.649837</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.614984</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.769411</td>\n",
       "      <td>0.795271</td>\n",
       "      <td>0.563302</td>\n",
       "      <td>0.709835</td>\n",
       "      <td>0.757461</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>0.477963</td>\n",
       "      <td>0.697460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608336</td>\n",
       "      <td>0.605960</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.553375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>0.706079</td>\n",
       "      <td>0.909540</td>\n",
       "      <td>0.657783</td>\n",
       "      <td>0.521838</td>\n",
       "      <td>0.696994</td>\n",
       "      <td>0.881162</td>\n",
       "      <td>0.649521</td>\n",
       "      <td>0.607425</td>\n",
       "      <td>0.892417</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.684472</td>\n",
       "      <td>0.557271</td>\n",
       "      <td>0.517675</td>\n",
       "      <td>0.630551</td>\n",
       "      <td>0.608336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877891</td>\n",
       "      <td>0.702744</td>\n",
       "      <td>0.494326</td>\n",
       "      <td>0.539094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>0.743158</td>\n",
       "      <td>0.911273</td>\n",
       "      <td>0.747477</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.720370</td>\n",
       "      <td>0.862063</td>\n",
       "      <td>0.641219</td>\n",
       "      <td>0.617279</td>\n",
       "      <td>0.902851</td>\n",
       "      <td>0.718953</td>\n",
       "      <td>0.752863</td>\n",
       "      <td>0.554026</td>\n",
       "      <td>0.516812</td>\n",
       "      <td>0.691407</td>\n",
       "      <td>0.605960</td>\n",
       "      <td>0.877891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707775</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.562359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>0.807694</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.803624</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.837447</td>\n",
       "      <td>0.678865</td>\n",
       "      <td>0.630920</td>\n",
       "      <td>0.858176</td>\n",
       "      <td>0.751671</td>\n",
       "      <td>0.547340</td>\n",
       "      <td>0.582969</td>\n",
       "      <td>0.739875</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.702744</td>\n",
       "      <td>0.707775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.590105</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.741511</td>\n",
       "      <td>0.548375</td>\n",
       "      <td>0.519003</td>\n",
       "      <td>0.627460</td>\n",
       "      <td>0.449931</td>\n",
       "      <td>0.555095</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.682606</td>\n",
       "      <td>0.671054</td>\n",
       "      <td>0.617638</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.494326</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>0.653801</td>\n",
       "      <td>0.478901</td>\n",
       "      <td>0.605224</td>\n",
       "      <td>0.817004</td>\n",
       "      <td>0.806833</td>\n",
       "      <td>0.570924</td>\n",
       "      <td>0.538682</td>\n",
       "      <td>0.605162</td>\n",
       "      <td>0.481711</td>\n",
       "      <td>0.571102</td>\n",
       "      <td>0.664174</td>\n",
       "      <td>0.738415</td>\n",
       "      <td>0.747119</td>\n",
       "      <td>0.623549</td>\n",
       "      <td>0.553375</td>\n",
       "      <td>0.539094</td>\n",
       "      <td>0.562359</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cuisine       brazilian   british  cajun_creole   chinese  filipino    french  \\\n",
       "cuisine                                                                         \n",
       "brazilian      1.000000  0.660232      0.742318  0.580756  0.769216  0.756392   \n",
       "british        0.660232  1.000000      0.591218  0.467640  0.631355  0.859609   \n",
       "cajun_creole   0.742318  0.591218      1.000000  0.605572  0.746146  0.708829   \n",
       "chinese        0.580756  0.467640      0.605572  1.000000  0.839802  0.540446   \n",
       "filipino       0.769216  0.631355      0.746146  0.839802  1.000000  0.682939   \n",
       "french         0.756392  0.859609      0.708829  0.540446  0.682939  1.000000   \n",
       "greek          0.695691  0.562750      0.688392  0.496088  0.607435  0.759935   \n",
       "indian         0.687271  0.560349      0.618959  0.553532  0.655934  0.624868   \n",
       "irish          0.665712  0.926681      0.635178  0.460745  0.641009  0.837383   \n",
       "italian        0.740536  0.632625      0.738159  0.555511  0.670636  0.835281   \n",
       "jamaican       0.778319  0.662056      0.780897  0.635951  0.792722  0.723224   \n",
       "japanese       0.555604  0.508299      0.532385  0.835587  0.748561  0.540283   \n",
       "korean         0.571440  0.447177      0.578643  0.866828  0.782623  0.502205   \n",
       "mexican        0.743743  0.560464      0.724866  0.561849  0.678316  0.666848   \n",
       "moroccan       0.669009  0.543260      0.649837  0.505655  0.614984  0.685384   \n",
       "russian        0.706079  0.909540      0.657783  0.521838  0.696994  0.881162   \n",
       "southern_us    0.743158  0.911273      0.747477  0.558514  0.720370  0.862063   \n",
       "spanish        0.807694  0.604000      0.803624  0.603526  0.727408  0.817541   \n",
       "thai           0.685539  0.445518      0.590105  0.755813  0.741511  0.548375   \n",
       "vietnamese     0.653801  0.478901      0.605224  0.817004  0.806833  0.570924   \n",
       "\n",
       "cuisine          greek    indian     irish   italian  jamaican  japanese  \\\n",
       "cuisine                                                                    \n",
       "brazilian     0.695691  0.687271  0.665712  0.740536  0.778319  0.555604   \n",
       "british       0.562750  0.560349  0.926681  0.632625  0.662056  0.508299   \n",
       "cajun_creole  0.688392  0.618959  0.635178  0.738159  0.780897  0.532385   \n",
       "chinese       0.496088  0.553532  0.460745  0.555511  0.635951  0.835587   \n",
       "filipino      0.607435  0.655934  0.641009  0.670636  0.792722  0.748561   \n",
       "french        0.759935  0.624868  0.837383  0.835281  0.723224  0.540283   \n",
       "greek         1.000000  0.640296  0.583670  0.859279  0.681281  0.469467   \n",
       "indian        0.640296  1.000000  0.577336  0.616218  0.734926  0.567997   \n",
       "irish         0.583670  0.577336  1.000000  0.649883  0.680913  0.494765   \n",
       "italian       0.859279  0.616218  0.649883  1.000000  0.695776  0.510289   \n",
       "jamaican      0.681281  0.734926  0.680913  0.695776  1.000000  0.584691   \n",
       "japanese      0.469467  0.567997  0.494765  0.510289  0.584691  1.000000   \n",
       "korean        0.479834  0.538853  0.458797  0.522574  0.609202  0.819832   \n",
       "mexican       0.696644  0.708641  0.591736  0.733982  0.731874  0.506555   \n",
       "moroccan      0.769411  0.795271  0.563302  0.709835  0.757461  0.477404   \n",
       "russian       0.649521  0.607425  0.892417  0.697593  0.684472  0.557271   \n",
       "southern_us   0.641219  0.617279  0.902851  0.718953  0.752863  0.554026   \n",
       "spanish       0.837447  0.678865  0.630920  0.858176  0.751671  0.547340   \n",
       "thai          0.519003  0.627460  0.449931  0.555095  0.650898  0.682606   \n",
       "vietnamese    0.538682  0.605162  0.481711  0.571102  0.664174  0.738415   \n",
       "\n",
       "cuisine         korean   mexican  moroccan   russian  southern_us   spanish  \\\n",
       "cuisine                                                                       \n",
       "brazilian     0.571440  0.743743  0.669009  0.706079     0.743158  0.807694   \n",
       "british       0.447177  0.560464  0.543260  0.909540     0.911273  0.604000   \n",
       "cajun_creole  0.578643  0.724866  0.649837  0.657783     0.747477  0.803624   \n",
       "chinese       0.866828  0.561849  0.505655  0.521838     0.558514  0.603526   \n",
       "filipino      0.782623  0.678316  0.614984  0.696994     0.720370  0.727408   \n",
       "french        0.502205  0.666848  0.685384  0.881162     0.862063  0.817541   \n",
       "greek         0.479834  0.696644  0.769411  0.649521     0.641219  0.837447   \n",
       "indian        0.538853  0.708641  0.795271  0.607425     0.617279  0.678865   \n",
       "irish         0.458797  0.591736  0.563302  0.892417     0.902851  0.630920   \n",
       "italian       0.522574  0.733982  0.709835  0.697593     0.718953  0.858176   \n",
       "jamaican      0.609202  0.731874  0.757461  0.684472     0.752863  0.751671   \n",
       "japanese      0.819832  0.506555  0.477404  0.557271     0.554026  0.547340   \n",
       "korean        1.000000  0.516476  0.477963  0.517675     0.516812  0.582969   \n",
       "mexican       0.516476  1.000000  0.697460  0.630551     0.691407  0.739875   \n",
       "moroccan      0.477963  0.697460  1.000000  0.608336     0.605960  0.784612   \n",
       "russian       0.517675  0.630551  0.608336  1.000000     0.877891  0.702744   \n",
       "southern_us   0.516812  0.691407  0.605960  0.877891     1.000000  0.707775   \n",
       "spanish       0.582969  0.739875  0.784612  0.702744     0.707775  1.000000   \n",
       "thai          0.671054  0.617638  0.533128  0.494326     0.536965  0.606200   \n",
       "vietnamese    0.747119  0.623549  0.553375  0.539094     0.562359  0.614200   \n",
       "\n",
       "cuisine           thai  vietnamese  \n",
       "cuisine                             \n",
       "brazilian     0.685539    0.653801  \n",
       "british       0.445518    0.478901  \n",
       "cajun_creole  0.590105    0.605224  \n",
       "chinese       0.755813    0.817004  \n",
       "filipino      0.741511    0.806833  \n",
       "french        0.548375    0.570924  \n",
       "greek         0.519003    0.538682  \n",
       "indian        0.627460    0.605162  \n",
       "irish         0.449931    0.481711  \n",
       "italian       0.555095    0.571102  \n",
       "jamaican      0.650898    0.664174  \n",
       "japanese      0.682606    0.738415  \n",
       "korean        0.671054    0.747119  \n",
       "mexican       0.617638    0.623549  \n",
       "moroccan      0.533128    0.553375  \n",
       "russian       0.494326    0.539094  \n",
       "southern_us   0.536965    0.562359  \n",
       "spanish       0.606200    0.614200  \n",
       "thai          1.000000    0.914986  \n",
       "vietnamese    0.914986    1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the results to a DataFrame\n",
    "cuisine_list = cuisine_ingredients.index\n",
    "cuisine_similarity = pd.DataFrame(cuisine_similarity, index=cuisine_list, columns=cuisine_list)\n",
    "cuisine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18b81710>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the similarities as a heatmap\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(cuisine_similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
